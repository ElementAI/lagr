model_type: transformer_lagr
data_path: /cogs
data: cogs
weak_supervision: False
supervised: True
share_encoder: False
separate_encoders: True
model_type: transformer_lagr
batch_size: 128
lr: 0.0001
dropout: 0.4
epochs: 400 
dim: 512
num_warmup_steps: 0
transformer.encoder_n_layers: 4
transformer.decoder_n_layers: 4
transformer.n_heads: 4
n_graph_layers: 1
n_node_labels: 646
n_edge_labels: 11
eval_every: 20
